model_list:
  # Anthropic Models
  - model_name: claude-opus-4
    litellm_params:
      model: anthropic/claude-opus-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY
  - model_name: claude-sonnet-4
    litellm_params:
      model: anthropic/claude-sonnet-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY

  # OpenAI Models
  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      api_key: os.environ/OPENAI_API_KEY
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY

  # Gemini Models
  - model_name: gemini-2.5-pro
    litellm_params:
      model: gemini/gemini-2.5-pro
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash
      api_key: os.environ/GEMINI_API_KEY

  # Local: Ollama (configure OLLAMA_BASE_URL, e.g. http://bytebot-ollama:11434)
  - model_name: ollama-llama3.1-8b
    litellm_params:
      model: ollama/llama3.1:8b
      api_base: os.environ/OLLAMA_BASE_URL

  # Local: Generic OpenAI-compatible endpoint (e.g., FastAPI following OpenAI spec)
  # Set LOCAL_OPENAI_BASE to http://your-fastapi:8000/v1 and, if needed, LOCAL_OPENAI_API_KEY
  - model_name: local-openai-compat
    litellm_params:
      model: openai/gpt-4o-mini
      api_base: os.environ/LOCAL_OPENAI_BASE
      api_key: os.environ/LOCAL_OPENAI_API_KEY
